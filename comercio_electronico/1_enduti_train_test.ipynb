{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "enduti_usuarios_anual_2020=pd.read_csv(r'data\\conjunto_de_datos_endutih_2020_csv\\conjuntos_de_datos\\tr_endutih_usuario_anual_2020.csv', dtype=\"object\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "enduti_usuarios_anual_2021=pd.read_csv(r'data\\conjunto_de_datos_endutih_2021_csv\\conjuntos_de_datos\\tr_endutih_usuario_anual_2021.csv', dtype=\"object\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enduti_usuarios_anual_2022=pd.read_csv(r'data\\conjunto_de_datos_endutih_2022_csv\\conjunto_de_datos\\tr_endutih_usuarios_anual_2022.csv', dtype=\"object\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "enduti_usuarios_anual_2023=pd.read_csv(r'data\\conjunto_de_datos_endutih_2023_csv\\conjunto_de_datos\\tr_endutih_usuarios_anual_2023.csv', dtype=\"object\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed dataframe for 2020: shape (2048, 6)\n",
      "Transformed dataframe for 2021: shape (2048, 6)\n",
      "Transformed dataframe for 2022: shape (2048, 6)\n",
      "Transformed dataframe for 2023: shape (2048, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the age bins and labels\n",
    "age_bins = [6, 17, 24, 30, 35, 45, 55, 65, float('inf')]\n",
    "age_labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "\n",
    "# List of dataframes and the years corresponding to them\n",
    "dataframes = [\n",
    "    ('2020', enduti_usuarios_anual_2020),\n",
    "    ('2021', enduti_usuarios_anual_2021),\n",
    "    ('2022', enduti_usuarios_anual_2022),\n",
    "    ('2023', enduti_usuarios_anual_2023)\n",
    "]\n",
    "\n",
    "# Dictionary to store transformed dataframes\n",
    "transformed_dataframes = {}\n",
    "\n",
    "for year, df in dataframes:\n",
    "    # Convert 'EDAD' to numeric\n",
    "    df['EDAD'] = pd.to_numeric(df['EDAD'])\n",
    "    \n",
    "    # Create age groups\n",
    "    df['GRUPO_EDAD'] = pd.cut(df['EDAD'], bins=age_bins, labels=age_labels)\n",
    "    \n",
    "    # Convert 'FAC_PER' to numeric\n",
    "    df['FAC_PER'] = pd.to_numeric(df['FAC_PER'])\n",
    "    \n",
    "    # Check if the column name for the year is 'P7_19' or 'P7_21'\n",
    "    p7_column = 'P7_21' if year == '2023' else 'P7_19'\n",
    "    \n",
    "    # Group by relevant columns including the P7 column\n",
    "    grouped_df = df.groupby(['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO', p7_column], observed=False).agg({'FAC_PER': 'sum'}).reset_index()\n",
    "    \n",
    "    # Pivot the dataframe to have the P7 column values as separate columns\n",
    "    pivoted_df = grouped_df.pivot_table(\n",
    "        index=['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO'], \n",
    "        columns=p7_column, \n",
    "        values='FAC_PER', \n",
    "        fill_value=0,\n",
    "        observed=False\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    pivoted_df.columns = ['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO', 'FAC_PER_P7_19_1', 'FAC_PER_P7_19_2']\n",
    "    \n",
    "    # Store the transformed dataframe in the dictionary\n",
    "    transformed_dataframes[year] = pivoted_df\n",
    "\n",
    "    # Display the shape of the transformed dataframe for each year\n",
    "    print(f\"Transformed dataframe for {year}: shape {pivoted_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume transformed_dataframes is the dictionary with the transformed DataFrames\n",
    "df_2020 = transformed_dataframes['2020']\n",
    "df_2021 = transformed_dataframes['2021']\n",
    "df_2022 = transformed_dataframes['2022']\n",
    "df_2023 = transformed_dataframes['2023']\n",
    "\n",
    "# Ensure that the categories are aligned (e.g., categorical columns are of the same type)\n",
    "categorical_features = ['GRUPO_EDAD', 'SEXO', 'ESTRATO']\n",
    "\n",
    "# Convert 'ENT' to integer type\n",
    "for df in [df_2020, df_2021, df_2022, df_2023]:\n",
    "    df['ENT'] = df['ENT'].astype(int)\n",
    "\n",
    "# Convert categorical columns to string for consistency\n",
    "for col in categorical_features:\n",
    "    for df in [df_2020, df_2021, df_2022, df_2023]:\n",
    "        df[col] = df[col].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the combined \"prev\" dataset with the 2022 target\n",
    "merged_df_2020_2022 = pd.merge(\n",
    "    df_2020, \n",
    "    df_2022[['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO', 'FAC_PER_P7_19_1', 'FAC_PER_P7_19_2']],\n",
    "    on=['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Merge the combined \"prev\" dataset with the 2023 target\n",
    "merged_df_2021_2023 = pd.merge(\n",
    "    df_2021, \n",
    "    df_2023[['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO', 'FAC_PER_P7_19_1', 'FAC_PER_P7_19_2']],\n",
    "    on=['GRUPO_EDAD', 'SEXO', 'ENT', 'ESTRATO'],\n",
    "    how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m CatBoostRegressor(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train the model for FAC_PER_P7_19_1\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Make predictions for FAC_PER_P7_19_1\u001b[39;00m\n\u001b[0;32m     24\u001b[0m predictions_1 \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict(train_pool_1)\n",
      "File \u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\asesoria-ecom-antadf\\.venv\\Lib\\site-packages\\catboost\\core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\asesoria-ecom-antadf\\.venv\\Lib\\site-packages\\catboost\\core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\samue\\Documents\\GitHub\\asesoria-ecom-antadf\\.venv\\Lib\\site-packages\\catboost\\core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "# Concatenate the two merged datasets\n",
    "combined_df = pd.concat([merged_df_2020_2022, merged_df_2021_2023], ignore_index=True)\n",
    "combined_df = combined_df[combined_df['FAC_PER_P7_19_1_y'] > 0]\n",
    "\n",
    "# Split features and target\n",
    "X_train = combined_df.drop(columns=['FAC_PER_P7_19_1_y', 'FAC_PER_P7_19_2_y'])\n",
    "y_train = combined_df['FAC_PER_P7_19_1_y']\n",
    "\n",
    "\n",
    "# Specify categorical columns for CatBoost\n",
    "cat_features_indices = [X_train.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "# Create a CatBoost Pool for FAC_PER_P7_19_1\n",
    "train_pool_1 = Pool(data=X_train, label=y_train, cat_features=cat_features_indices)\n",
    "\n",
    "# Initialize the CatBoost Regressor for FAC_PER_P7_19_1\n",
    "model_1 = CatBoostRegressor(iterations=2000, learning_rate=0.1, depth=16, verbose=0)\n",
    "\n",
    "# Train the model for FAC_PER_P7_19_1\n",
    "model_1.fit(train_pool_1)\n",
    "\n",
    "# Make predictions for FAC_PER_P7_19_1\n",
    "predictions_1 = model_1.predict(train_pool_1)\n",
    "\n",
    "# Display the first few predictions alongside the actual values for FAC_PER_P7_19_1\n",
    "print(\"Predictions for FAC_PER_P7_19_1:\")\n",
    "for pred, actual in zip(predictions_1[:20], y_train[:20]):\n",
    "    print(f\"Predicted: {pred:.2f}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for FAC_PER_P7_19_1:\n",
      "R-squared: 0.9550\n",
      "Mean Percentage Error (MPE): 29.92%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate mean percentage error (MPE) with zero-value handling\n",
    "def mean_percentage_absolute_error(y_true, y_pred):\n",
    "    # Mask to exclude zero values in y_true to prevent division by zero\n",
    "    mask = y_true != 0\n",
    "    return np.mean(abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "# Calculate R-squared and mean percentage error for FAC_PER_P7_19_1\n",
    "r2_1 = r2_score(y_train, predictions_1)\n",
    "mpe_1 = mean_percentage_absolute_error(y_train, predictions_1)\n",
    "\n",
    "print(\"\\nEvaluation Metrics for FAC_PER_P7_19_1:\")\n",
    "print(f\"R-squared: {r2_1:.4f}\")\n",
    "print(f\"Mean Percentage Error (MPE): {mpe_1:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
